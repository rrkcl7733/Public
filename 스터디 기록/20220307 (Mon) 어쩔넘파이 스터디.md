# 20220307 (Mon) 어쩔넘파이 스터디



# 내일 정리 해놓을게요 오늘 보실 분들은 정리가 아직 안돼있지만 오늘만 이렇게 봐주세용~!





## 1. Errors



- 403 error

```python
import ssl

headers = {'User-Agent': 'Chrome/66.0.3359.181'}
req = urllib.request.Request(df['URL'][0], headers=headers)
context = ssl._create_unverified_context()
html = urlopen(req, context=context)
soup_tmp = BeautifulSoup(html.read(), 'html.parser')
```



## 2. 질문 & 정보

> 완택: 161p {date}



> github에 jupyter notebook 올렸을 때 지도가 출력되지 않는 문제 --> 미해결(django로 polium 지도 띄울 수 있는 웹사이트 따로 만들 수 있다..)

- import 형식이라 안 되고, 따로 그림 형식으로만 올릴 수 있다.
- https://docs.github.com/en/repositories/working-with-files/using-files/working-with-non-code-files
- http://nbviewer.org/



> find와 select?

\#### soup.find와 soup.select의 차이

- `find`는 `html tag`를 통한 크롤링,  `select`는 `css`를 통한 크롤링에 쓰인다. 
- - 첫 번째 태그를 찾는 것은 `find, select_one `함수이고 모든 태그를 찾는 것은 `find_all, select `함수 
  - - 가장 큰 차이점은 `select`는` > `로 하위태그를 쉽게 찾을 수 있다. 
    - - 예를 들어`head `태그 아래있는` title`태그를 찾고 싶다고 할때, `select`가 더 직관적인 형태로 태그를 찾을 수 있다. 
      - - `find_all - class_='outertext'`-> 첫 번째 태그 가져옴



> 승훈: tqdm warning 뜨지 않도록 하는 법

```python
from tqdm import notebook

for n in notebook.tqdm(df.index): # 이렇게 쓰니까 워닝이 안뜨네
```



> 교수님

tak — 오늘 오후 9:17 import requests url = "https://movie.naver.com/movie/sdb/rank/rmovie.nhn?sel=cur&date=2021-12-12" response = requests.get(url).text print(response) 김혜린 — 오늘 오후 9:19 교수님 이거 beautifulsoup 안쓰고 가져오는 방법인가요?.? tak — 오늘 오후 9:19 urllib 말고 편하게 쓰는 법이요 BeautifulSoup은 써야해요 ㅋㅋㅋㅋ 혹은 selenium

```python
import requests
url = "https://movie.naver.com/movie/sdb/rank/rmovie.nhn?sel=cur&date=2021-12-12"
response = requests.get(url).text 
html = urlopen(request).read().decode()
soup_tmp = BeautifulSoup(html, "html.parser")
soup_tmp
```

![img](20220303%20(Thu)%20%EC%96%B4%EC%A9%94%EB%84%98%ED%8C%8C%EC%9D%B4%20%EC%8A%A4%ED%84%B0%EB%94%94.assets/unknown.png)

> 혜린

- 정규표현식
- \n, \r\n



> 경욱

https://namu.wiki/w/robots.txt

크롤링할 때 robots.txt 잘 읽어보기



## 3. 회고



> 완택

크롤링 많이 해봤었는데, 복습을 많이 안하다보니까 할 때마다 까먹어서 오늘부터 복습하고 정리해서 해야겠다.



> 경욱

예전에 크롤링 해볼 때는 태그의 의미들도 잘 모르고, 구성도 잘 모른 채로 했었는데, 최근에 html이나 bootstrap 해보면서 좀 친해졌다 생각한다. p라든지 div 등등.. 지금 와서 보니까 저번에 했던 생각이 나면서 처음 했던 거 보다는 빠르게 이해를 할 수 있었다.



> 승훈

정처기, 이것저것 하고 있었는데 이제 좀 진득하게 할 수 있는 시간이 생겨가지고 1, 2장 복습도 할 수 있을 것 같다.



> 하평

승훈님과 비슷하게 정처기 공부 한다고 집중을 많이 못했는데 못했던 부분들도 많이 해야 할 것 같다. 마지막 pivot 테이블에서 막혀 있는데 오류 잘 해결해서 잘 해보고 싶다.



> 미애

1, 2장을 좀 제대로 못해서 3장을 계속 봤는데 에러도 똑같은 부분이 나왔다. 또 뭔가 html 이런 내용 나오고, url 다루는 관통 프로젝트도 했었는데, 낯이 익으면서도 좀 어색한 느낌으로 쓰면서 이렇게 쓸 수도 있구나라고 느꼈다. 뭔가 자연스럽게 관통당하고 있다는 느낌이 들었다.



> 혜린

3장 하면서 조금 더 숨통이 트이는 느낌. 말씀해주신대로 더 익숙한 느낌이고 수업 시간에 배웠던 html 기반으로 크롤링을 하는 것이다보니 